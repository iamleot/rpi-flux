---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: flux-system
spec:
  chart:
    spec:
      chart: kube-prometheus-stack
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
      version: 80.4.2
  install:
    crds: Create
    createNamespace: true
  interval: 10m0s
  releaseName: kube-prometheus-stack
  storageNamespace: prometheus
  targetNamespace: prometheus
  upgrade:
    crds: CreateReplace
  # XXX: Double-check the order of the targetPath defined here and in
  # XXX: spec.valuesFrom!
  valuesFrom:
    - kind: Secret
      name: slack-api-url
      valuesKey: slack_api_url
      targetPath: alertmanager.config.global.slack_api_url
    - kind: Secret
      name: discord-webhook-url
      valuesKey: discord_webhook_url
      targetPath: alertmanager.config.receivers[1].discord_configs[0].webhook_url
    - kind: Secret
      name: telegram-bot
      valuesKey: bot_token
      targetPath: alertmanager.config.receivers[3].telegram_configs[0].bot_token
    - kind: Secret
      name: telegram-bot
      valuesKey: chat_id
      targetPath: alertmanager.config.receivers[3].telegram_configs[0].chat_id
  values:
    additionalPrometheusRulesMap:
      custom-kube-prometheus-stack-node-exporter:
        groups:
          - name: custom-node-exporter
            rules:
              - alert: NodeMemoryHighUtilization
                annotations:
                  description: |
                    Memory is filling up at {{ $labels.instance }}, has been above 95% for the last 15 minutes, is currently at {{ printf "%.2f" $value }}%.
                  runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodememoryhighutilization
                  summary: Host is running out of memory.
                expr: 100 - (node_memory_MemAvailable_bytes{job="node-exporter"} / node_memory_MemTotal_bytes{job="node-exporter"}
                  * 100) > 95
                for: 15m
                labels:
                  severity: warning
    alertmanager:
      config:
        route:
          group_by: ['namespace']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 12h
          receiver: 'null'
          routes:
            - receiver: 'null'
              matchers:
                - alertname =~ "InfoInhibitor|Watchdog"
            - receiver: 'discord'
              continue: true
            - receiver: 'slack'
              continue: true
            - receiver: 'telegram'
              continue: true
        # XXX: Double-check the order of the receivers defined here and in
        # XXX: spec.valuesFrom!
        receivers:
          - name: 'null'
          - name: 'discord'
            discord_configs:
              - send_resolved: true
                title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}{{ if .CommonLabels.job }} for {{ .CommonLabels.job }}{{end}}'
                message: |-
                  {{ range .Alerts }}
                    **Alert:** {{ .Annotations.summary }} - `{{ .Labels.severity }}`
                    **Description:** {{ .Annotations.description }}
                    **Status:** {{ .Status }}
                    **Details:**
                    {{ range .Labels.SortedPairs }} • **{{ .Name }}:** `{{ .Value }}`
                    {{ end }}
                  {{ end }}
          - name: 'slack'
            slack_configs:
              - send_resolved: true
                channel: '#rpi-alerts'
                title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}{{ if .CommonLabels.job }} for {{ .CommonLabels.job }}{{end}}'
                text: |-
                  {{ range .Alerts }}
                    *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
                    *Description:* {{ .Annotations.description }}
                    *Status:* {{ .Status }}
                    *Details:*
                    {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
                    {{ end }}
                  {{ end }}
          - name: 'telegram'
            telegram_configs:
              - send_resolved: true
                message: |-
                  [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}{{ if .CommonLabels.job }} for {{ .CommonLabels.job }}{{end}}
                  {{ range .Alerts }}
                    Alert: {{ .Annotations.summary }} - {{ .Labels.severity }}
                    Description: {{ .Annotations.description }}
                    Status: {{ .Status }}
                    Details:
                    {{ range .Labels.SortedPairs }} • {{ .Name }}: {{ .Value }}
                    {{ end }}
                  {{ end }}
    defaultRules:
      disabled:
        NodeMemoryHighUtilization: true
      rules:
        etcd: false
        kubeControllerManager: false
        kubeProxy: false
        kubeScheduler: false
    grafana:
      enabled: false
      forceDeployDashboards: true
      forceDeployDatasources: true
    kubeControllerManager:
      enabled: false
    kubeEtcd:
      enabled: false
    kubeProxy:
      enabled: false
    kubeScheduler:
      enabled: false
    prometheus:
      prometheusSpec:
        retention: 7d
        storageSpec:
          volumeClaimTemplate:
            spec:
              resources:
                requests:
                  storage: 10Gi
        volumeMounts:
          - name: consoles
            mountPath: /etc/prometheus/consoles
        volumes:
          - name: consoles
            configMap:
              name: consoles
              defaultMode: 0444
